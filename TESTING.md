# ğŸ§ª droid2api v2.0 Testing Guide

Complete testing suite for the Universal API Gateway supporting OpenAI, Anthropic, and Gemini formats.

---

## ğŸ“‹ Test Suite Overview

| Test File | Format | Tool | What It Tests |
|-----------|--------|------|---------------|
| `test_all_endpoints.sh` | All 3 | Bash/cURL | Core API endpoints with JSON validation |
| `test_openai.py` | OpenAI | Python SDK | OpenAI SDK integration & streaming |
| `test_anthropic.py` | Anthropic | Python SDK | Anthropic SDK integration & multi-turn |
| `test_gemini.py` | Gemini | Python SDK | Gemini SDK integration & chat |
| `run_all_tests.sh` | All 3 | Master Runner | Runs all tests in sequence |

---

## ğŸš€ Quick Start

### Option 1: Run All Tests

```bash
# Install Python dependencies
pip install -r test_requirements.txt

# Run complete test suite
chmod +x run_all_tests.sh
./run_all_tests.sh
```

### Option 2: Run Individual Tests

```bash
# Bash/cURL tests
chmod +x test_all_endpoints.sh
./test_all_endpoints.sh

# OpenAI Python SDK
python3 test_openai.py

# Anthropic Python SDK
python3 test_anthropic.py

# Gemini Python SDK
python3 test_gemini.py
```

---

## ğŸ“¦ Prerequisites

### Required

- **Node.js** 18+ (for running droid2api)
- **Bash** (for shell scripts)
- **curl** (for HTTP requests)
- **jq** (for JSON parsing)

```bash
# Install jq on Ubuntu/Debian
sudo apt-get install jq

# Install jq on macOS
brew install jq
```

### Optional (for Python tests)

- **Python 3.8+**
- **pip** (Python package manager)

```bash
# Install Python dependencies
pip install -r test_requirements.txt

# Or install individually
pip install openai anthropic google-generativeai
```

---

## ğŸ”§ Configuration

All tests use environment variables for configuration:

```bash
# Port (default: 3000)
export PORT=3000

# Model to test (default: glm-4.6)
export MODEL=glm-4.6

# Authentication token (default: any)
export AUTH_TOKEN=your_token_here
```

**Example:**
```bash
export PORT=3000
export MODEL=claude-sonnet-4
export AUTH_TOKEN=my-secret-token

./run_all_tests.sh
```

---

## ğŸ“‹ Test 1: Bash/cURL Tests

**File**: `test_all_endpoints.sh`

Tests all endpoints using raw HTTP requests with cURL.

### What It Tests

1. âœ… **OpenAI format** - `/v1/chat/completions`
2. âœ… **Anthropic format** - `/v1/messages`
3. âœ… **Gemini format** - `/v1/generateContent`
4. âœ… **Models endpoint** - `/v1/models`

### Run

```bash
chmod +x test_all_endpoints.sh
./test_all_endpoints.sh
```

### Example Output

```
=========================================
ğŸ§ª Testing droid2api Universal Gateway
=========================================
Base URL: http://localhost:3000
Model: glm-4.6
=========================================

âœ“ Server is running

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ Test 1: OpenAI Chat Completions Format
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Endpoint: POST /v1/chat/completions
Expected Response: OpenAI format

Response:
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "Python is a high-level programming language."
    },
    "finish_reason": "stop"
  }],
  "usage": {...}
}

âœ“ OpenAI format validated
âœ“ Response content: Python is a high-level programming language.

[... more tests ...]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‰ All tests passed! Universal Gateway is working!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ Test 2: OpenAI Python SDK

**File**: `test_openai.py`

Tests using the official OpenAI Python SDK.

### What It Tests

1. âœ… **Non-streaming chat** - Basic request/response
2. âœ… **Streaming response** - Real-time token streaming
3. âœ… **Response metadata** - Usage stats, finish reason
4. âœ… **SDK compatibility** - Works with official SDK

### Run

```bash
python3 test_openai.py
```

### Example Code

```python
from openai import OpenAI

client = OpenAI(
    base_url=f"http://localhost:{PORT}/v1",
    api_key="any"
)

response = client.chat.completions.create(
    model="glm-4.6",
    messages=[{
        "role": "user",
        "content": "What is Python?"
    }],
    stream=False
)

print(response.choices[0].message.content)
```

### Example Output

```
==================================================
ğŸ§ª Testing OpenAI Chat Completions Format
==================================================
Base URL: http://localhost:3000/v1
Model: glm-4.6
==================================================

Sending request to /v1/chat/completions...

Response received!

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Response Content:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Python is a high-level, interpreted programming language.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Response Metadata:
  ID: chatcmpl-123
  Model: glm-4.6
  Finish Reason: stop
  Tokens Used:
    Prompt: 15
    Completion: 12
    Total: 27

âœ… OpenAI format test PASSED!

[... streaming test ...]

==================================================
ğŸ‰ OpenAI format tests complete!
==================================================
```

---

## ğŸ Test 3: Anthropic Python SDK

**File**: `test_anthropic.py`

Tests using the official Anthropic Python SDK.

### What It Tests

1. âœ… **Non-streaming messages** - Basic request/response
2. âœ… **Streaming response** - Real-time token streaming
3. âœ… **Multi-turn conversation** - Context handling
4. âœ… **Response metadata** - Token usage, stop reason

### Run

```bash
python3 test_anthropic.py
```

### Example Code

```python
from anthropic import Anthropic

client = Anthropic(
    base_url=f"http://localhost:{PORT}",
    api_key="any"
)

response = client.messages.create(
    model="glm-4.6",
    max_tokens=1024,
    messages=[{
        "role": "user",
        "content": "What is Python?"
    }]
)

print(response.content[0].text)
```

### Example Output

```
==================================================
ğŸ§ª Testing Anthropic Messages Format
==================================================
Base URL: http://localhost:3000
Model: glm-4.6
==================================================

Sending request to /v1/messages...

Response received!

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Response Content:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Python is a high-level, interpreted programming language.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Response Metadata:
  ID: msg_123
  Model: glm-4.6
  Role: assistant
  Stop Reason: end_turn
  Tokens Used:
    Input: 15
    Output: 12

âœ… Anthropic format test PASSED!

[... streaming and multi-turn tests ...]

==================================================
ğŸ‰ Anthropic format tests complete!
==================================================
```

---

## ğŸ Test 4: Gemini Python SDK

**File**: `test_gemini.py`

Tests using the official Google Gemini SDK.

### What It Tests

1. âœ… **Non-streaming generation** - Basic request/response
2. âœ… **Streaming response** - Real-time chunk streaming
3. âœ… **Multi-turn chat** - Conversation history
4. âœ… **System instructions** - Role-based responses

### Run

```bash
python3 test_gemini.py
```

### Example Code

```python
import google.generativeai as genai

genai.configure(
    api_key="any",
    transport="rest",
    client_options={"api_endpoint": f"http://localhost:{PORT}"}
)

model = genai.GenerativeModel("glm-4.6")
response = model.generate_content("What is Python?")

print(response.text)
```

### Example Output

```
==================================================
ğŸ§ª Testing Gemini GenerateContent Format
==================================================
Base URL: http://localhost:3000
Model: glm-4.6
==================================================

Initializing Gemini model...
Sending request to /v1/generateContent...

Response received!

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Response Content:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Python is a high-level, interpreted programming language.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Response Metadata:
  Finish Reason: STOP
  Safety Ratings: 4 categories
  Tokens Used:
    Prompt: 15
    Candidates: 12
    Total: 27

âœ… Gemini format test PASSED!

[... streaming, chat, and system instruction tests ...]

==================================================
ğŸ‰ Gemini format tests complete!
==================================================
```

---

## ğŸ¯ Complete Test Suite

**File**: `run_all_tests.sh`

Master test runner that executes all tests in sequence.

### Features

- âœ… Runs all bash and Python tests
- âœ… Checks for dependencies
- âœ… Provides detailed error reporting
- âœ… Color-coded output
- âœ… Final summary with pass/fail status

### Run

```bash
chmod +x run_all_tests.sh
./run_all_tests.sh
```

### Example Output

```
=========================================
ğŸ§ª droid2api v2.0 Complete Test Suite
=========================================

âœ“ Python 3 found: Python 3.10.12
âœ“ All dependencies installed

Configuration:
  Port: 3000
  Model: glm-4.6
  Auth Token: any

=========================================

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ Running Bash/cURL Tests
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[... bash tests output ...]

âœ“ Bash tests completed successfully

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ Running OpenAI Python SDK Tests
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[... OpenAI tests output ...]

âœ“ OpenAI tests completed successfully

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ Running Anthropic Python SDK Tests
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[... Anthropic tests output ...]

âœ“ Anthropic tests completed successfully

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ Running Gemini Python SDK Tests
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[... Gemini tests output ...]

âœ“ Gemini tests completed successfully

=========================================
ğŸ“Š Complete Test Summary
=========================================

âœ“ Bash/cURL Tests: PASSED
âœ“ OpenAI Python SDK Tests: PASSED
âœ“ Anthropic Python SDK Tests: PASSED
âœ“ Gemini Python SDK Tests: PASSED

=========================================
ğŸ‰ ALL TESTS PASSED!
Universal Gateway is working perfectly!
=========================================
```

---

## ğŸ› Troubleshooting

### Issue: "Server is not running"

**Solution:**
```bash
# Start droid2api first
npm start

# Then run tests in another terminal
./run_all_tests.sh
```

---

### Issue: "jq: command not found"

**Solution:**
```bash
# Ubuntu/Debian
sudo apt-get install jq

# macOS
brew install jq

# Windows (WSL)
sudo apt-get install jq
```

---

### Issue: "Module not found: openai"

**Solution:**
```bash
# Install Python dependencies
pip install -r test_requirements.txt

# Or install individually
pip install openai anthropic google-generativeai
```

---

### Issue: Connection refused

**Cause:** droid2api not running or wrong port

**Solution:**
```bash
# Check if server is running
curl http://localhost:3000/v1/models

# If not, start it
npm start

# Check port
export PORT=3000  # Or your custom port
```

---

### Issue: Authentication errors

**Cause:** Backend requires valid auth token

**Solution:**
```bash
# Set your auth token
export AUTH_TOKEN=your_real_token_here

# Then run tests
./run_all_tests.sh
```

---

## ğŸ“Š CI/CD Integration

### GitHub Actions

```yaml
name: Test droid2api

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          npm install
          pip install -r test_requirements.txt
          sudo apt-get install -y jq
      
      - name: Start droid2api
        run: npm start &
        env:
          PORT: 3000
      
      - name: Wait for server
        run: sleep 5
      
      - name: Run tests
        run: ./run_all_tests.sh
        env:
          PORT: 3000
          MODEL: glm-4.6
          AUTH_TOKEN: test-token
```

---

## ğŸ¯ Test Coverage

### Endpoints Tested

- âœ… `GET /v1/models` - List available models
- âœ… `POST /v1/chat/completions` - OpenAI format
- âœ… `POST /v1/messages` - Anthropic format
- âœ… `POST /v1/generateContent` - Gemini format

### Features Tested

- âœ… Non-streaming responses
- âœ… Streaming responses (where supported)
- âœ… Multi-turn conversations
- âœ… System instructions
- âœ… Token usage metadata
- âœ… Error handling
- âœ… Format validation
- âœ… SDK compatibility

### Response Format Validation

- âœ… OpenAI `choices[0].message.content`
- âœ… Anthropic `content[0].text`
- âœ… Gemini `candidates[0].content.parts[0].text`
- âœ… Usage metadata for all formats
- âœ… Proper HTTP status codes

---

## ğŸ’¡ Pro Tips

### Tip 1: Test Different Models

```bash
# Test with different models
export MODEL=claude-sonnet-4
./run_all_tests.sh

export MODEL=gpt-4
./run_all_tests.sh

export MODEL=gemini-2.5-pro
./run_all_tests.sh
```

### Tip 2: Test Different Ports

```bash
# Test on different port
export PORT=8080
npm start &

export PORT=8080
./run_all_tests.sh
```

### Tip 3: Run Specific Test

```bash
# Only test OpenAI
python3 test_openai.py

# Only test bash endpoints
./test_all_endpoints.sh
```

### Tip 4: Verbose Output

```bash
# Enable debug output
export DEBUG=1
./run_all_tests.sh
```

---

## ğŸš€ Next Steps

After all tests pass:

1. âœ… **Deploy to production** - Tests confirm gateway works
2. âœ… **Add to CI/CD** - Automate testing on every commit
3. âœ… **Monitor in production** - Watch for format issues
4. âœ… **Add custom tests** - Test your specific use cases

**Your Universal API Gateway is production-ready!** ğŸ‰

